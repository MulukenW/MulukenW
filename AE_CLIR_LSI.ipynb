{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7DphwkCQ1KlyJZTpCzQsg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MulukenW/MulukenW/blob/main/AE_CLIR_LSI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "807zNHMxRtdz",
        "outputId": "e6efbea0-825c-4ae5-b882-0862503b528b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document: እንዴት ነህ, Similarity: 0.3853154182434082\n",
            "Document: መልካም ጊዜ ይሁንልኝ, Similarity: 0.3717384934425354\n",
            "Document: እንኳን ደህና መጣህ, Similarity: 0.37173840403556824\n",
            "Document: ሰላም እንዴት ነህ, Similarity: 0.37173840403556824\n",
            "Document: እንኳን ደህና መጣህ, Similarity: 0.37173840403556824\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Load pre-trained model tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "# Function to get embeddings\n",
        "def get_embeddings(texts):\n",
        "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Sample data\n",
        "amharic_docs = [\n",
        "    \"እንኳን ደህና መጣህ\",\n",
        "    \"እንዴት ነህ\",\n",
        "    \"ሰላም እንዴት ነህ\",\n",
        "    \"እንኳን ደህና መጣህ\",\n",
        "    \"መልካም ጊዜ ይሁንልኝ\"\n",
        "]\n",
        "english_docs = [\n",
        "    \"Welcome\",\n",
        "    \"How are you\",\n",
        "    \"Hello how are you\",\n",
        "    \"Welcome back\",\n",
        "    \"Have a good time\"\n",
        "]\n",
        "\n",
        "# Get embeddings for documents\n",
        "amharic_embeddings = get_embeddings(amharic_docs)\n",
        "english_embeddings = get_embeddings(english_docs)\n",
        "\n",
        "# Example query\n",
        "query = \"good time\"\n",
        "query_embedding = get_embeddings([query])[0]  # Ensure query embedding is 1-D\n",
        "\n",
        "# Cross-lingual retrieval function\n",
        "def find_similar_documents(query_embedding, embeddings, docs):\n",
        "    similarities = [1 - cosine(query_embedding, doc_embedding) for doc_embedding in embeddings]\n",
        "    sorted_docs = sorted(zip(docs, similarities), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_docs\n",
        "\n",
        "# Find similar Amharic documents for the English query\n",
        "results = find_similar_documents(query_embedding, amharic_embeddings, amharic_docs)\n",
        "\n",
        "# Print results\n",
        "for doc, similarity in results:\n",
        "    print(f\"Document: {doc}, Similarity: {similarity}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Load pre-trained model tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "# Function to get embeddings\n",
        "def get_embeddings(texts):\n",
        "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    # Add language-specific preprocessing here\n",
        "    return text\n",
        "\n",
        "# Sample data\n",
        "amharic_docs = [\n",
        "    \"እንኳን ደህና መጣህ\",\n",
        "    \"እንዴት ነህ\",\n",
        "    \"ሰላም እንዴት ነህ\",\n",
        "    \"እንኳን ደህና መጣህ\",\n",
        "    \"መልካም ጊዜ ይሁንልኝ\"\n",
        "]\n",
        "english_docs = [\n",
        "    \"Welcome\",\n",
        "    \"How are you\",\n",
        "    \"Hello how are you\",\n",
        "    \"Welcome back\",\n",
        "    \"Have a good time\"\n",
        "]\n",
        "\n",
        "# Preprocess documents\n",
        "amharic_docs = [preprocess_text(doc) for doc in amharic_docs]\n",
        "english_docs = [preprocess_text(doc) for doc in english_docs]\n",
        "\n",
        "# Get embeddings for documents\n",
        "amharic_embeddings = get_embeddings(amharic_docs)\n",
        "english_embeddings = get_embeddings(english_docs)\n",
        "\n",
        "# Example query\n",
        "query = \"Hello\"\n",
        "query_embedding = get_embeddings([query])[0]  # Ensure query embedding is 1-D\n",
        "\n",
        "# Cross-lingual retrieval function\n",
        "def find_similar_documents(query_embedding, embeddings, docs):\n",
        "    similarities = cosine_similarity([query_embedding], embeddings)[0]\n",
        "    sorted_docs = sorted(zip(docs, similarities), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_docs\n",
        "\n",
        "# Find similar Amharic documents for the English query\n",
        "results = find_similar_documents(query_embedding, amharic_embeddings, amharic_docs)\n",
        "\n",
        "# Print results\n",
        "for doc, similarity in results:\n",
        "    print(f\"Document: {doc}, Similarity: {similarity}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ8o-Oo3TC3j",
        "outputId": "e42453b4-94f1-42b9-c3dc-9546946181c3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document: እንዴት ነህ, Similarity: 0.41250312328338623\n",
            "Document: መልካም ጊዜ ይሁንልኝ, Similarity: 0.37651732563972473\n",
            "Document: እንኳን ደህና መጣህ, Similarity: 0.3765171766281128\n",
            "Document: ሰላም እንዴት ነህ, Similarity: 0.3765171766281128\n",
            "Document: እንኳን ደህና መጣህ, Similarity: 0.3765171766281128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "def evaluate_retrieval(queries, relevant_docs, document_embeddings, documents):\n",
        "    all_results = []\n",
        "    for query, relevant in zip(queries, relevant_docs):\n",
        "        query_embedding = get_embeddings([query])[0]\n",
        "        results = find_similar_documents(query_embedding, document_embeddings, documents)\n",
        "        retrieved_docs = [doc for doc, _ in results]\n",
        "        # Compute precision, recall, etc.\n",
        "        precision = sum([1 for doc in retrieved_docs if doc in relevant]) / len(retrieved_docs)\n",
        "        recall = sum([1 for doc in retrieved_docs if doc in relevant]) / len(relevant)\n",
        "        all_results.append((precision, recall))\n",
        "    avg_precision = np.mean([res[0] for res in all_results])\n",
        "    avg_recall = np.mean([res[1] for res in all_results])\n",
        "    return avg_precision, avg_recall\n",
        "\n",
        "# Sample queries and relevant documents for evaluation\n",
        "queries = [\"Hello\", \"Good time\"]\n",
        "relevant_docs = [[\"ሰላም እንዴት ነህ\", \"እንዴት ነህ\"], [\"መልካም ጊዜ ይሁንልኝ\"]]\n",
        "\n",
        "# Evaluate the retrieval system\n",
        "avg_precision, avg_recall = evaluate_retrieval(queries, relevant_docs, amharic_embeddings, amharic_docs)\n",
        "print(f\"Average Precision: {avg_precision}, Average Recall: {avg_recall}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEwdPNgfWPq4",
        "outputId": "76b1ab0e-87df-48cc-9c52-64c2752f4483"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Precision: 0.30000000000000004, Average Recall: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vDmb_FIyWUiN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}